= The Modified Euler Algorithm

== A Wild Idea

*Dan*: Well, Erica, how are we going to move up to a more accurate
algorithm?

*Carol*: You mentioned something about a second-order scheme.

*Erica*: Yes, and there are several different choices.  With our
first-order approach, we had little choice.  Forward Euler was the
obvious one: just follow your nose, the way it is pointed at the 
beginning of the step, as in fig. ref(forward1).

*Dan*: You mentioned a backward Euler as well, and even drew a picture,
in in fig. ref(backward1).

*Erica*: That was only because you asked me about it!  And the backward
Euler scheme is not an explicit method.  It is an implicit method, where
you have to know the answer before give calculate it.  As we discussed, you
can solve that through iteration; but in that case you have to redo every
step at least one more time, so you spend a lot more computer time and
you still only have a first-order method, so there is really no good reason
to use that method.

*Carol*: But wait a minute, the two types of errors in figs. ref(forward1)
and ref(backward1) are clearly going in the opposite directions.
I mean, forward flies out of the curve one way, and backward spirals in
the other way.  I wonder, can't you somehow combine the two methods and
see whether we can let the two errors cancel each other?

If we combine the previous two pictures, the most natural thing would be
to try _both_ of the Euler types, forward and backward.  Here is a sketch,
in fig. ref(modforward1).  The top arrow is what we've done so far,
forward Euler, simply following the tangent line of the curve.  The
bottom line is backward Euler, taking a step that lands on a curve
with the right tangent at the end.  My idea is to compute both, and then
take the average between the two attempts.  I'm sure that would give a
better approximation!

:figure: modforward1.eps 6cm modforward1
An attempt to improve the Euler methods.  The top arrow shows forward Euler,
and the bottom arrow backward Euler.  The dashed arrow shows the average
between the two, which clearly gives a better approximation to the curved
lines that show the true solutions to the differential equation.

*Dan*: But at a large cost!  The backward Euler method is an implicit
method, as Erica mentioned, that requires at least one extra iteration.
So the bottom arrow alone is much more expensive to compute than the top
arrow, and we have to compute both.

*Carol*: It was just a wild idea, and it may not be useful.

== Backward and Forward

*Erica*: Actually, I like Carol's idea.  In reminds me of one of the second
order schemes that I learned in class.  Let me just check my notes.

Aha, I found it.  There is an algorithm called "Modified Euler", which
starts with the forward Euler idea, and then modifies it to improve the
accuracy, from first order to second order.  And it seems rather similar
to what Carol just sketched.

*Carol*: In that case, how about trying to reconstruct it for ourselves.
That is more fun than copying the algorithm from a book.

Now let's see.  We want to compute the dashed line in figure ref(modforward1).
How about shifting the arrow of the backward step to the end
of the arrow of the forward step, as in fig. ref(modforward2)?  Or to be
precise, how about just taking two forward Euler steps, one after the other?
The second forward step will not produce exactly the same arrow as the first
backward step, but it will be almost the same arrow, and perhaps such an
approximation would be good enough.

:figure: modforward2.eps 6cm modforward2
Two successive forward Euler steps.

*Dan*: But how are you going to use that to construct the dashed line in
fig. ref(modforward1)?

*Carol*: How about shifting the second arrow back, in fig. ref(modforward2),
so that the end of the arrow falls on the same point as the end of the
first arrow?  In that way, we have constructed a backward Euler step
that lands on the same point where our forward Euler step landed, as
you can see in fig. ref(modforward3).

:figure: modforward3.eps 6cm modforward3
A forward Euler steps and a backward Euler step, landing at the same point.

As I already admitted, the top arrow in fig. ref(modforward3) is not exactly
the same arrow as the bottom arrow in fig. ref(modforward1), but the two
arrows are approximately the same, especially if our step sizes are
not too large.  So, in a first approximation, we can average the arrows
in fig. ref(modforward3).  This will make Carol happy: no more implicit
steps.  We have only taken forward steps, even though we recycle the
second one by interpreting it as a backward step.

The simplest way to construct the average between the two vectors is by
adding them and then dividing the length by two.  Here it is, in
fig. ref(modforward4).

:figure: modforward4.eps 6cm modforward4
The new integration scheme produces the dashed arrow, as exactly one-half of
the some of the two fully drawn arrows; the dotted arrow has the same length
as the dashed arrow.  This result is approximately the same as the dashed
arrow in fig. ref(modforward1).

== On Shaky Ground

*Dan*: I don't believe it.  Or what I really mean is: I cannot yet believe
that this is really correct, because I don't see any proof for it.  You are
waving your arms and you just hope for the best.  Let's be a bit more
critical here.

In figure ref(modforward1), it was still quite plausible that the
dashed arrow succeeded in canceling the opposite errors in the two
solid arrows.  Given that those two solid arrows, corresponding to
forward Euler and backward Euler, were only first-order accurate, I
can see that the error in the dashed arrow just _may_ be second-order
accurate.  Whether the two first-order errors of the solid arrows
_actually_ cancel in leading order, I'm not sure, but we might be lucky.

But then you start introducing other assumptions: that you can swap
the new second forward Euler arrow for the old backward Euler error,
and stuff like that.  I must say, here I have totally lost my intuition.

Frankly, I feel on really shaky ground, talking about an order of a
differential equation.  I have some vague sense of what it could mean,
but I wouldn't be able to define it.

*Erica*: Here is the basic idea.  If an algorithm is <i>n</i>th order,
this means that it makes an error per step that is one order higher
in terms of powers of the time step.  What I mean is this: for a simple
differential equation

:equation:
{dx \over dt} = f(x)

the error that we make in going from time
<tex>$i$</tex> to time <tex>$i+1$</tex>, with <tex>$dt = t_{i+1}-t_i$</tex>,
can be written as:

:equation:
\delta x_{i+1} = B(dt)^{n+1}

Here the coefficient <tex>$B$</tex> is a function of
<tex>$x$</tex>, but it is almost independent of the size of the time
step <tex>$dt$</tex>, and in the limit that <tex>$dt\rightarrow
0$</tex>, it  will converge to a constant value
<tex>$B(x,dt)\rightarrow B(x)$</tex>, which in the general case will
be proportional to the <i>(n+1)</i>th time derivative of
<tex>$f(x(t))$</tex>, along the orbit <tex>$x(t)$</tex>.

In practice, we want to integrate an orbit over a given finite interval
of time, for example from <tex>$t=0$</tex> to
<tex>$t=T$</tex>.  For a choice of step size <tex>$dt$</tex>, we then
need <tex>$k = T/dt$</tex> integration steps.  If we assume that the
errors simply add up, in other words, if we don't rely on the errors
to cancel each other in some way, then the total integration error
after <tex>$k$</tex> steps will be bounded by

:equation:
\delta x(T) < kC(dt)^{n+1} = {T\over dt}C(dt)^{n+1} = TC(dt)^n

where <tex>$C$</tex> is proportional to an upper bound of the absolute
value of the <i>(n+1)</i>th time derivative of <tex>$f(x(t))$</tex>,
along the orbit <tex>$x(t)$</tex>.

In other words, for an <i>n</i>th order algorithm, the error we make
after integrating for a fixed finite amount of time scales like the
<i>n</i>th power of the time step.

*Dan*: If we apply this reasoning to the forward Euler algorithm,
which is a first order algorithm, we find that the accumulated error
over a fixed time interval scales like the first power of time.  Yes,
that makes sense: when we have made the time step ten times smaller,
for example in sections ref(sect:validation) and
ref(sect:evenbetternumbers), we have found that the error became
roughly ten times smaller.

*Carol*: So if the modified Euler algorithm is really a second-order
algorithm, we should be able to reduce the error by a factor one hundred,
when we make the time step ten times smaller.

*Erica*: Yes, that's the idea, and that would be great!  Let's write
a code for it, so that we can try it out.

== Specifying the Steps

*Carol*: It should be easy to implement this new modified Euler scheme.
The picture we have drawn shows the change in position of a particle, and we
should apply the same idea to the change in velocity.

For starters, let us just look at the position.  First we have to
introduce some notation.

*Erica*: In the literature, people often talk about predictor-corrector
methods.  The idea is that you first make a rough prediction about a
future position, and then you make a correction, after you have
evaluated the forces at that predicted position.

In our case, in fig. ref(modforward4), the first solid arrow starts at
the original point <tex>$\br_i$</tex>.  Let us call the end point of that
arrow <tex>$\br_{i+1, p}$</tex>, where the _p_ stands for _predicted_,
as the predicted result of taking a forward Euler step:

:equation:
\label{riplus1p}
\br_{i+1, p} = \br_i + \bv_i dt

The second arrow shows another prediction, namely for yet another
forward Euler step, which lands us at <tex>$\br_{i+2, p}$</tex>:

:equation:
\br_{i+2, p} = \br_{i+1, p} + \bv_{i+1, p} dt

*Dan*: But here you are using the velocity at time <tex>$i+1$</tex>,
something that you haven't calculated yet.

*Erica*: I know, we'll come to that in a moment, when we write down the
velocity equivalent for Eq. (ref(riplus1p)).  I just wanted to write
the position part first.  If we had <tex>$\bv_{i+1, p}$</tex>, we could
then find the _corrected_ new position by taking the average of the
first two forward Euler steps, as indicated in fig. ref(modforward4):

:eqnarray:
\label{ModEulerStepLong}
\br_{i+1, c} & = & \br_i + 
\half\left\{\left(\br_{i+1, p} - \br_i\right)+
           \left(\br_{i+2, p} - \br_{i+1, p}\right)\right\}    \nonumber \\
& = & \br_i + \half\left(\br_{i+2, p} - \br_i\right)           \nonumber \\
& = & \half\left(\br_i + \br_{i+2, p}\right)

*Carol*: As Dan pointed out, we have to do a similar thing for the velocities.
I guess that everything carries over, but with <tex>$\bv$</tex> instead
of <tex>$\br$</tex> and <tex>$\ba$</tex> instead of <tex>$\bv$</tex>.

*Erica*: Yes, in fact it is just a matter of differentiating the previous
lines with respect to time.  Putting it all together, we then get calculate
all that we need in the following order, from predicted to corrected
quantities:

:eqnarray:
\label{ModEulerStep}
\br_{i+1, p} & = & \br_i + \bv_i dt                           \nonumber \\
\bv_{i+1, p} & = & \bv_i + \ba_i dt                           \nonumber \\
\br_{i+2, p} & = & \br_{i+1, p} + \bv_{i+1, p} dt             \nonumber \\
\bv_{i+2, p} & = & \bv_{i+1, p} + \ba_{i+1, p} dt             \nonumber \\
\br_{i+1, c} & = & \half\left(\br_i + \br_{i+2, p}\right)     \nonumber \\
\bv_{i+1, c} & = & \half\left(\bv_i + \bv_{i+2, p}\right)

*Dan*: Just on time delivery, as they say: <tex>$\bv_{i+1, p}$</tex>
is calculated just before it is needed in calculating
<tex>$\br_{i+2, p}$</tex>, just as Erica correctly predicted
(no pun intended).

== Implementation

*Carol*: Here is the new code.
I'll call it <tt>euler_modified_10000_steps_sparse.rb</tt>.  Let's
hope we have properly modified the original Euler:

 :inccode: .euler_modified_10000_steps_sparse.rb

== Experimentation

*Carol*: 
As you can see I am giving it time steps of size 0.001, just to be on
the safe side.  Remember, in the case of plain old forward Euler, when
we chose that step size, we got
figure ref(euler_elliptic_10000_steps_sparse_ok).  Presumably, we will
get a more accurate orbit integration this time.  Let's try it!

 :commandoutput: ruby euler_modified_10000_steps_sparse.rb > euler_modified_10000_steps_sparse.out
 :commandinput: gnuplot END
set term post eps
set output "euler_modified_10000_steps_sparse.ps"
set size ratio -1
plot "euler_modified_10000_steps_sparse.out"
quit
END

:figure: euler_modified_10000_steps_sparse.ps 10cm euler_modified_10000_steps_sparse
First attempt at modified Euler integration, with step size
<tex>$dt=0.001$</tex>.

Here are the results, in figure ref(euler_modified_10000_steps_sparse).

*Dan*: Wow!!!  Too good to be true.  I can't even see deviations from the
true elliptic orbit!  This is just as good as what we got for forward
Euler with a hundred times more work, in figure
ref(euler_elliptic_1000000_steps_sparse_ok).

*Erica*: fifty times more work, you mean.  In figure
ref(euler_elliptic_1000000_steps_sparse_ok), we had used time steps of 
<tex>$10^{-5}$</tex>, a hundred times smaller than the time steps of
<tex>$10^{-3}$</tex> that we used in figure ref(euler_modified_10000_steps_sparse);
but in our modified Euler case, each step requires twice as much work.

*Dan*: Ah, yes, you're right.  Well, I certainly don't mind doing twice
as much work per step, if I have to do far fewer than half the number
of steps!

== Simplification

*Carol*: Let's try to do even less work, to see how quickly things get bad.
Here, I'll make the time step that is ten times larger, in the file
<tt>euler_modified_1000_steps.rb</tt>.  This also makes life a little
simpler, because now we no longer have to sample: we can produce one
output for each step, in order to get our required one thousand outputs:

 :inccode: .euler_modified_1000_steps.rb

*Carol*: 
This approach should need just twice as much work as our very first attempt
at integrating the elliptic orbit, which resulted in failure, even
after we had corrected our initial typo, as we could see in figure ref(euler).

 :commandoutput: ruby euler_modified_1000_steps.rb > euler_modified_1000_steps.out
 :commandinput: gnuplot END
set term post eps
set output "euler_modified_1000_steps.ps"
set size ratio -1
plot "euler_modified_1000_steps.out"
quit
END

:figure: euler_modified_1000_steps.ps 10cm euler_modified_1000_steps
Second attempt at modified Euler integration, with step size
<tex>$dt=0.01$</tex>.

*Erica*: Again, this is far better than what we saw in figure ref(euler).
There we couldn't even complete a single orbit!

== Second Order Scaling

*Dan*: Yes, it seems clear that our modified Euler behaves a lot better
than forward Euler.  But we have not yet convinced ourselves that it is
really second order.  We'd better test it, to make sure.

*Carol*: Good idea.  Here is a third choice of time step, ten times smaller
than our original choice, in file
<tt>euler_modified_100000_steps_sparse.rb</tt>:

 :inccode: .euler_modified_100000_steps_sparse.rb

With the three choices of time step, we can now compare the last output
lines in all three cases:

 :commandoutput: ruby euler_modified_1000_steps.rb | tail -1

 :commandoutput: ruby euler_modified_10000_steps_sparse.rb | tail -1

 :commandoutput: ruby euler_modified_100000_steps_sparse.rb | tail -1

Well, that's pretty clear, isn't it?  The difference between the last
two results is about one hundred times smaller, that the difference
between the first two results.

In other words, if we take the last outcome as being close to the true
result, then the middle result has an error that it about one hundred
times smaller than the first result.  The first result has a time step
that is ten times larger than the second result.  Therefore, making the
time step ten times smaller gives a result that is about one hundred
times more accurate.  We can congratulate ourselves: we have clearly
crafted a second-order integration algorithm!
