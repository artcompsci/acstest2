= Partitioned Runge-Kutta Algorithms

*Bob*: You promised a better approach to solving second-order differential
equations, using Runge-Kutta schemes.  What did you call such an algorithm
again?

*Alice*: It is called a partitioned Runge-Kutta algorithm.  The idea is to
combine the force calculations in different ways for the position and for
the velocity.  The word `partitioned' here means that separate the treatment
of <tex>$x$</tex> from the treatment of <tex>$v$</tex>.  We already saw
an example at the end of our previous discussion, where we had found a
scheme that was almost, but not quite, a leapfrog scheme.  If we would have
tinkered with that scheme, we could have turned it into a leapfrog,
but it would then no longer be a vector generalization of a
Runge-Kutta scheme.

*Bob*: So you're saying that we have a lot more freedom, when we allow
separate ways to update position and velocity, after first calculation
a number of force evaluations.

*Alice*: Exactly.  And we have already done this, for our fourth-order
integrator, the one we plucked from Abramowitz and Stegun.

*Bob*: Does this mean that we can write our good old leapfrog as a partitioned
Runge-Kutta scheme?  That would be interesting!  I have always thought about
Runge-Kutta methods and the leapfrog scheme as two completely different
animals, pardon the pun.  Do you think that the leapfrog can be view
as a type of Runge-Kutta algorithm?

*Alice*: I'm not sure.  One reason to do this systematic landscape exploration
is to find the answers to that type of question!  And I'm sure we'll
find out soon.  By exploring all possible schemes with up to two new
force calculations per step, we're bound to encounter the leapfrog, if
indeed it is a citizen of the Runge-Kutta world.

So let us return to our special second-order differential equation

:equation:
{d^{\,2}x \over dt^2} = f(x).

Let us first gather
some useful expressions, starting with the two first-order equations

:equation:
\left\{ \begin{array}{lcl}
{\displaystyle {dx \over dt}} &=& v \\
\phantom{1}&\phantom{1}&\phantom{1} \\
{\displaystyle {dv \over dt}} &=& f(x)
\end{array} \right.

As before, we expand the position and the velocity of the orbit in
Taylor series:

:eqnarray:
x_1 &=& x_0 + v_0\tau + \half a_0\tau^2 + \one{6} j_0\tau^3 +
\one{24} s_0\tau^4 + \one{120} c_0\tau^5 + \one{720} p_0\tau^6
+ O(\tau^7) \ \ \ \ \ \ \ \    \\
v_1 &=& v_0 + a_0\tau + \half j_0\tau^2 + \one{6} s_0\tau^3 +
\one{24} c_0\tau^4 + \one{120} p_0\tau^5 + O(\tau^6)

and when we differentiate the set of differential equations several
times, we obtain the following equations:

:eqnarray:
a_0 &=& f(x(0)) \ \ = \ \ f(x_0) \ \ = \ \ f_0 \nonumber\\
\phantom{1}&\phantom{1}&\phantom{1}                    \nonumber\\
j_0 &=& \left.{d \over dt} a(t)\right|_{t=0}\!\! =
\left.{d \over dt} f(x(t))\right|_{t=0}\!\! =
\left.{df(x) \over dx}\right|_{x=x_0} \left.{dx \over dt}\right|_{t=0}\!\! =
f_0' v_0                                               \nonumber\\
\phantom{1}&\phantom{1}&\phantom{1}                    \nonumber\\
s_0 &=& \dot j_0 \ \ = \ \ f_0'' v_0^2 + f_0' f_0  \nonumber\\
\phantom{1}&\phantom{1}&\phantom{1}                    \nonumber\\
c_0 &=& \dot s_0 \ \ = \ \ f_0''' v_0^3 + 3f_0'' f_0 v_0 +
(f_0')^2 v_0                                           \nonumber\\ 
\phantom{1}&\phantom{1}&\phantom{1}                    \nonumber\\
p_0 &=& \dot c_0 \ \ = \ \ f_0'''' v_0^4 + 6f_0''' f_0 v_0^2 +
f_0''\left\{3f_0^2 + 5f_0' v_0^2\right\} + (f_0')^2 f_0

The last three lines can be derived in the same way as the second line,
by fully writing out the differentiations, using the chain rule.  This
derivation is completely analogous to what we did for our first-order
differential equation.

== One Force Evaluation per Step

*Bob*: I guess we will forget about force recycling, at least for now.

*Alice*: Yes.  To keep things simple, let us look at a single integration
step.  But we have another choice to make.

In the case of a first-order differential equation, at the start of
our integration we can only evaluate the right-hand side at time zero,
at the beginning of the integration time step.  If we simply follow
that example, we start with:

:equation:
k_1 = f(x_0)

This leads to the following dimensionally correct expressions:

:eqnarray:
\label{array1a}
x_1 &=& x_0 + \alpha_0 v_0 \tau + \alpha_1 k_1\tau^2  \\
v_1 &=& v_0 + \beta_1 k_1\tau   

We can write the expression for the position, substituting
<tex>$k_1$</tex>, as

:equation:
\label{simplex}
x_1 = x_0 + \alpha_0 v_0 \tau + \alpha_1 f_0\tau^2

We have to compare this with the Taylor series

:equation:
\label{taylor4x}
x_1 = x_0 + v_0\tau + \half a_0\tau^2
+ \one{6} j_0\tau^3  + O(\tau^4) 

Using Eqs. (XXXXX)
we can write this as

:equation:
\label{taylor4fx}
x_1 = x_0 + v_0\tau + \half f_0\tau^2
+ \one{6} v_0f_0'\tau^3  + O(\tau^4)

Comparing Eqs. (ref(simplex)) and (ref(taylor4fx)), we find:

:equation:
\fbox{
$\displaystyle{
\alpha_0 = 1
}$
}

and

:equation:
\fbox{
$\displaystyle{
\alpha_1 = \half
}$
}

We cannot satisfy the third order term in <tex>$\tau$</tex>, so as far
as the expression for the position is concerned, we can make our scheme
second-order accurate.

Looking now at the velocity, we have

:equation:
\label{simplev}
v_1 = v_0 + \beta_1 f_0\tau   

We have to compare this with the Taylor series

:equation:
\label{taylor4v}
v_1 = v_0 + a_0\tau + \half j_0\tau^2
+ \one{6} s_0\tau^3  + O(\tau^4) 

Using Eqs. (XXXXX)
we can write this as

:equation:
\label{taylor4fv}
v_1 = v_0 + f_0\tau + \half v_0f_0'\tau^2 + O(\tau^4)

Comparing Eqs. (ref(simplev)) and (ref(taylor4fv)), we find from the
terms that are first order in <tex>$\tau$</tex>:

:equation:
\fbox{
$\displaystyle{
\beta_1 = 1
}$
}

Going to second order in <tex>$\tau$</tex> would require that

:equation:
j_0 = f_0' v_0 = 0

which cannot be true for general <tex>$f$</tex> and <tex>$v_0$</tex>.
Even though we can construct a second-order algorithm for the position,
we can only find a first-order algorithm for the velocity.

*Bob*: And I presume that there is no point in using a higher-order algorithm
for the position than for the velocity, since the overall order of the
integration scheme must be the lowest order of that of the components.
Hmmm.  Is that so?

*Alice*: Yes, that is correct.  For the very first step, it is possible in
this case to find a new position that is second-order accurate.  But
as soon as we take the second step, we use the velocity that we arrived
at in the first step, which is only first-order accurate.  The same is
true for each subsequent step: we always use the velocity value from
the previous step.

*Bob*: But each time we multiply the velocity with <tex>$\tau$</tex>.
So even though the velocity is first-order, the product of the velocity
with <tex>$\tau$</tex> must be second-order correct, leading to an error
term that is third-order in <tex>$\tau$</tex>.

*Alice*: Yes, that is formally correct.  However, \dots




We have to conclude that our approach only leads to a first-order correct
algorithm, which is of course the forward Euler algorithm:

:equation:
\left\{ \begin{array}{lcl}
x_1 &=& x_0 + v_0 \tau \\
v_1 &=& v_0 + k_1 \tau  \\
\phantom{1}&\phantom{1}&\phantom{1} \\
k_1 &=& f(x_0)
\end{array} \right.

%\subsubsubsection{A Delayed Force Evaluation}

{\bf 4.1.1.2. A Delayed Force Evaluation}

Given the special form of our second-order differential equation, it
is not necessary to start with a force evaluation at time zero.  The
first equation in the set

:equation:
\left\{ \begin{array}{lcl}
{\displaystyle {dx \over dt}} &=& v \\
\phantom{1}&\phantom{1}&\phantom{1} \\
{\displaystyle {dv \over dt}} &=& f(x)
\end{array} \right.

allows us to make a first-order prediction of the position, as:

:equation:
x(t) = x_0 + v_0 t + O(t^2)

which in turn allows us to postpone the first force evaluation to this
non-zero time:

:equation:
\dot v(t) = f(t) = f(x_0 + v_0 t + O(t^2)) = 
f(x_0 + v_0 t) + O(t^2).

Note that this trick is not possible for a general force term that
would depend on velocity as well.  In that case, the last equation
would read

:equation:
\dot v(t) = f(x(t), v(t)) = f(x_0 + v_0 t, v_0 + a_0 t) = 
f(x_0 + v_0 t, v_0 + f_0 t)

which would mean that we need an initial force evaluation <tex>$f_0$</tex> at
time zero, before we can perform a subsequent force evaluation at time <tex>$t$</tex>.

== xxx

Let us exploit this extra freedom, for our special differential equation,
by repeating our previous analysis for a delayed force evaluation.
Our first force evaluation can now take place at time <tex>$t = \eta_1 \tau$</tex>
where <tex>$\eta_1$</tex> is a free parameter.  Using the linear extrapolation of
the position, as sketched above, we obtain:

:equation:
\label{aha}
k_1 = f(x_0 + \eta_1 v_0 \tau) 

This leads to the following dimensionally correct expressions:

:eqnarray:
\label{array1b}
x_1 &=& x_0 + v_0 \tau + \alpha_1 k_1\tau^2  \\
v_1 &=& v_0 + \beta_1 k_1\tau   

If we expand <tex>$k_1$</tex> to first order in <tex>$\tau$</tex> , we obtain:

:equation:
k_1 = f_0 + \eta_1 f_0' v_0 \tau

Eq. (ref(array1b)) can thus be written as:

:equation:
\left\{ \begin{array}{lcl}
x_1 &=& x_0 + v_0 \tau + \alpha_1 f_0 \tau^2 
+ \alpha_1 \eta_1 f_0' v_0 \tau^3 + O(\tau^4)    \\
v_1 &=& v_0 + \beta_1 f_0\tau + \beta_1 \eta_1 f_0' v_0 \tau^2 + O(\tau^3)
\end{array} \right.

Comparing this with

:equation:
\label{taylor3x}
x_1 = x_0 + v_0\tau + \half a_0\tau^2
+ \one{6} j_0\tau^3  + O(\tau^4) 

<b>EXPAND</b>

let us first consider the <tex>$O(\tau^2)$</tex> terms, which leads to the
requirement:

:equation:
a_0 = f_0  = 2 \alpha_1 f_0

which leads to

:equation:
\alpha_1 = \half

Similarly, we can use the Taylor series for <tex>$v$</tex>:

:equation:
\label{taylor3v}
v_1 = v_0 + a_0\tau + \half j_0\tau^2
+ \one{6} s_0\tau^3  + O(\tau^4) 

<b>EXPAND</b>

Considering the <tex>$O(\tau)$</tex> term, we have:

:equation:
a_0 = f_0  = \beta_1 f_0

which leads to

:equation:
\beta_1 = 1

Considering the <tex>$O(\tau^2)$</tex> terms, we have:

:equation:
j_0 = f_0' v_0 = 2 \beta_1 \eta_1 f_0' v_0

This implies:

:equation:
\eta_1 = \half

In this way, all three free parameters are fixed, by requiring the
algorithm to be second-order in <tex>$O(\tau)$</tex> in both position and velocity.

Could it be that we are in luck, and that this fixed solution can give
us expressions for <tex>$x$</tex> and <tex>$v$</tex> that are also third-order correct in <tex>$O(\tau)$</tex> ?
Let us start with the position equation.  This would require:

:equation:
j_0 = f_0' v_0 = 6 \alpha_1 \eta_1 f_0' v_0

Alas, since we are forced to use <tex>$\alpha_1 = \eta_1 = \half$</tex> , the
coefficient on the right-hand side is <tex>$3/2$</tex> while the one on the
left-hand side is <tex>$1$</tex>.  We have no freedom left, so this equation has
no solutions for a general function <tex>$f$</tex> and a general initial velocity <tex>$v_0$</tex>.

%\subsubsubsection{Verlet-St\"ormer-Delambre Scheme}

{\bf 4.1.1.3. Verlet-St\"ormer-Delambre Scheme}

Using one evaluation of the right-hand side of the differential equation,
we have thus arrived at the following second-order integration scheme:

:equation:
\label{verlet}
\left\{ \begin{array}{lcl}
x_1 &=& x_0 + v_0 \tau + \half k_1 \tau^2  \\
v_1 &=& v_0 + k_1 \tau  \\
\phantom{1}&\phantom{1}&\phantom{1} \\
k_1 &=& f(x_0 + \half v_0 \tau)
\end{array} \right.       

Even though the equation for the velocity looks first-order, it is
actually second-order accurate, through the clever choice of time at
which the right-hand side of the differential equation is evaluated,
namely in between the times at which <tex>$v_0$</tex> and <tex>$v_1$</tex> are determined.

In fact, this scheme is nothing else than the good old leapfrog
algorithm, also known as the Verlet-St\"ormer-Delambre scheme, as we
will show now.

Define

:equation:
x_{1/2} \equiv x_0 + \half v_0 \tau

and

:equation:
v_{1/2} \equiv  v_0 + \half f_{1/2} \tau

where

:equation:
f_{1/2} \equiv f(x_{1/2}) = f(x_0 + \half v_0 \tau)

Our new scheme can then be written as

:equation:
\left\{ \begin{array}{lcl}
x_1 &=& x_0 + v_{1/2} \tau \\
v_1 &=& v_0 + f_{1/2} \tau
\end{array} \right.

Alternatively, we can express the first of these equations in terms of

:eqnarray:
x_{3/2} &=&  x_1 + \half v_1 \tau               \nonumber \\
&=& \left( x_0 + v_0\tau + \half f_{1/2}\tau^2 \right) +
\half \left( v_0 + f_{1/2}\tau \right) \tau            \nonumber \\
&=& x_{1/2} + \left( v_0 + f_{1/2}\tau \right) \tau            \nonumber \\
&=& x_{1/2} + v_1\tau

We have thus derived at expressions that show the leapfrog nature of
the algorithm most clearly:

:equation:
\left\{ \begin{array}{lcl}
x_{3/2} &=& x_{1/2} + v_1 \tau \\
v_1 &=& v_0 + f_{1/2} \tau
\end{array} \right.

This representation shows clearly that the equations are fully time
symmetric.  This fact was rather hidden in the original formulation,
eqs. (ref(verlet)).  However, if we explicitly take a step forward
and then another step backward, using eqs. (ref(verlet)), we can
recover the time symmetry inherent in these equations, as follows.
Let us denote the resulting position and velocity by <tex>$\{x_{-0}, v_{-0}\}$</tex> ,
which are obtained from <tex>$\{x_{1}, v_{1}\}$</tex> by taking a time step with
size <tex>$-\tau$</tex>.  Our task is to show that <tex>$\{x_{-0}, v_{-0}\}$</tex> actually
coincide with <tex>$\{x_{0}, v_{0}\}$</tex> , not only to second order, as would
be guaranteed in any second order scheme, but in fact to all orders in
<tex>$\tau$</tex>.

:eqnarray:
x_{-0} &=& x_1 - v_1 \tau + \half f(x_1 - \half v_1 \tau) \tau^2 \nonumber \\ 
&=& \left\{ x_0 + v_0 \tau + \half f(x_0 + \half v_0 \tau) \tau^2 \right\}
-\left\{v_0 + f(x_0 + \half v_0 \tau) \tau\right\}\tau +           \nonumber \\
&&\quad
\half f(\{x_0 + v_0 \tau + \half f(x_0 + \half v_0 \tau) \tau^2\}
- \half \{v_0 + f(x_0 + \half v_0 \tau) \tau\} \tau) \tau^2        \nonumber \\
&=& x_0 - \half f(x_0 + \half v_0 \tau) \tau^2 +       \nonumber \\
&&\quad
\half f(x_0 + v_0 \tau + \half f(x_0 + \half v_0 \tau) \tau^2
- \half v_0 \tau -\half f(x_0 + \half v_0 \tau) \tau^2) \tau^2     \nonumber \\
&=& x_0 - \half f(x_0 + \half v_0 \tau) \tau^2 +       \nonumber \\
&&\quad
\half f(x_0 + \half v_0 \tau) \tau^2                            \nonumber \\ 
&=& x_0

:eqnarray:
v_{-0} &=& v_1 - f(x_1 - \half v_1 \tau) \tau                     \nonumber \\
&=& \left\{v_0 + f(x_0 + \half v_0 \tau) \tau\right\}             \nonumber \\
&&\quad - f(\{x_0 + v_0 \tau + \half f(x_0 + \half v_0 \tau) \tau^2\}
- \half \{v_0 + f(x_0 + \half v_0 \tau) \tau\} \tau     \nonumber \\
&=& v_0

Finally, we can also write

:eqnarray:
x_{3/2} &=&  x_{1/2} + v_1 \tau           \nonumber \\
&=& x_{1/2} + v_0 \tau + f_{1/2} \tau^2           \nonumber \\
&=& x_{1/2} + v_{1/2} \tau + \half f_{1/2} \tau^2

and

:eqnarray:
v_{3/2} &=&  v_1 + \half f_{3/2} \tau           \nonumber \\
&=& v_0 + f_{1/2} \tau + \half f_{3/2} \tau           \nonumber \\
&=& v_{1/2} + \half \left( f_{1/2} + f_{3/2} \right) \tau

We thus find

:equation:
\left\{ \begin{array}{lcl}
x_{3/2} &=& x_{1/2} + v_{1/2}\tau + \half f_{1/2} \tau^2           \\
v_{3/2} &=& v_{1/2} + \half \left( f_{1/2} + f_{3/2} \right) \tau
\end{array} \right.

We can now shift our zero point in time by half a time step, to arrive
at the more convenient notation:

:equation:
\left\{ \begin{array}{lcl}
x_1 &=& x_0 + v_0\tau + \half f_0 \tau^2           \\
v_1 &=& v_0 + \half ( f_0 + f_1 ) \tau
\end{array} \right.

Comparing this with our starting point, eqs. (ref(verlet)):

:equation:
\left\{ \begin{array}{lcl}
x_1 &=& x_0 + v_0 \tau + \half k_1 \tau^2  \nonumber \\
v_1 &=& v_0 + k_1 \tau                 \nonumber  \\
\phantom{1}&\phantom{1}&\phantom{1}    \nonumber  \\
k_1 &=& f(x_0 + \half v_0 \tau)        \nonumber
\end{array} \right.       

we have arrived at the alternative formulation:

:equation:
\left\{ \begin{array}{lcl}
x_1 &=& x_0 + v_0 \tau + \half k_1 \tau^2  \\
v_1 &=& v_0 + (k_1 + k_2)\tau  \\
\phantom{1}&\phantom{1}&\phantom{1} \\
k_1 &=& f(x_0)        \\
k_2 &=& f(x_0 + v_0 + \half k_1 \tau^2)
\end{array} \right.

The second formulation seems rather different, in that it requires two
force calculations.  Note, however, that the position at which the
second force calculation takes place is _exactly_ the same
position at which the first force calculation for the next step will
take place.  Therefore, the second force calculation of each step can
be recycled as the first force calculation of the next step.
Effectively, we thus use only one force calculation per step.  This
trick is known in the literature as FSAL, short for First-Same-As-Last.
We will come back to this point below.

%\subsubsubsection{An Historical Note}

{\bf 4.1.1.4. An Historical Note}

Almost everywhere in the literature, Runge-Kutta methods are assumed
to start with <tex>$k_1 = f_0$</tex>: letting the first evaluation of the
right-hand side of the differential equation take place at the very
beginning of the step.  This is necessary in the general case, but not
for the special case of a second-order differential equation where
there is no velocity dependence in the force term.  The only place we
have found so far in the literature, which mentions the possibility of
starting with the force evaluation already at a later time is a
paragraph in <tex>Nystr\"om</tex> (1925),
the original paper introducing what is
now known as the <tex>Runge-Kutta-Nystr\"om</tex> algorithms.

In his section 2, p. 7, near the bottom, he remarks that, to be
consistent, we should allow the freedom to write a general expression
of the type we have done above in Eq. (ref(aha)).  He then adds that
he decided against considering this extra freedom, for two reasons,
both pragmatic, the first related to speed of execution of the
algorithms, the second related to speed of derivation of the
expressions fot the algorithms.  Here are his arguments.

First of all, we often know already the force evaluation at the
beginning of the step, from the last stage of the calculation of the
previous step (at least approximately; and using even earlier force
calculations, we can further improve the accuracy, without having to
perform new force evaluations).  Secondly, he adds, starting from such
a general expression has led him to such unwieldy expressions that he
was more or less forced to put <tex>$\eta_1 = 0$</tex> in his equivalent to our
Eq. (ref(aha)).

Of course, current availability of algebraic manipulation programs
have now invalidated his second argument.  Curiously, all text books
seem to propagate the simplifying assumption <tex>$\eta_1 = 0$</tex> without
questioning what the basis for this assumption may have been.

== Two Force Evaluations per Step

%\subsubsubsection{General Form}

{\bf 4.1.2.1. General Form}

If we allow two evaluations of the right-hand side of the differential
equation, we can work with the following general expression that is
dimensionally correct

:eqnarray:
k_1 &=& f(x_0 + \eta_{11} v_0\tau)    \\
k_2 &=& f(x_0 + \eta_{21} v_0\tau + \eta_{22} k_1 \tau^2)

which leads to the following expressions for position and velocity steps:

:eqnarray:
\label{array2a}
x_1 &=& x_0 + v_0 \tau + \left(\alpha_1 k_1 + \alpha_2 k_2\right) \tau^2  \\
v_1 &=& v_0 + \left(\beta_1 k_1 + \beta_2 k_2\right) \tau   

Substituting the <tex>$k_i$</tex> values, these equations expand into

:equation:
\left\{ \begin{array}{lcl}
x_1 &=&
x_0 \ +\  v_0 \tau \ +\  \alpha_1 f(x_0+\eta_{11} v_0 \tau) \tau^2\ +\  \\
\phantom{1}&\phantom{1}&\quad\quad\quad
\alpha_2 f(x_0+\eta_{21} v_0 \tau +
\eta_{22} f(x_0+\eta_{11} v_0 \tau) \tau^2) \tau^2 \\
\phantom{1}&\phantom{1}&\phantom{1} \\
v1 &=&
v_0\ +\  \beta_1 f(x_0+\eta_{11} v_0 \tau)\tau \ +\  \\
\phantom{1}&\phantom{1}&\quad\quad\ \ 
\beta_2 f(x_0+\eta_{21} v_0\tau+\eta_{22} f(x_0+\eta_{11} v_0 \tau) \tau^2)\tau
\end{array} \right.

So far, everything is still the exact prescription, given in the
original algorithmic scheme.  If we now expand the expressions in
powers of <tex>$\tau$</tex> , we get:

:equation:
\left\{ \begin{array}{lcl}
x_1 &=&
x_0 \ +\  v_0 \tau \ +\  (\alpha_1 + \alpha_2)f_0\tau^2\ +\  \\
\phantom{1}&\phantom{1}&\quad\quad\quad\quad\quad\quad\ 
(\alpha_1\eta_{11}+\alpha_2\eta_{21})f_0'v_0 \tau^3 \ +\  O(\tau^4) \\
\phantom{1}&\phantom{1}&\phantom{1} \\
v1 &=&
v_0\ +\  (\beta_1+\beta_2) f_0\tau \ +\  
(\beta_1\eta_{11}+\beta_2\eta_{21})f_0'v_0 \tau^2 \ +\   \\
\phantom{1}&\phantom{1}&\quad\quad\ \ \ 
(\half(\beta_1\eta_{11}^2+\beta_2\eta_{21}^2)f_0''v_0^2 +
\beta_2\eta_{22}f_0f_0')\tau^3\ +\  O(\tau^4) \\
\end{array} \right.

This should be equal to the Taylor series:

:eqnarray:
x_1 &=& x_0 + v_0\tau + \half a_0\tau^2 + \one{6} j_0\tau^3 +
\one{24} s_0\tau^4 + O(\tau^5) \ \ \ \ \ \ \ \    \\
v_1 &=& v_0 + a_0\tau + \half j_0\tau^2 + \one{6} s_0\tau^3 +
\one{24} c_0\tau^4 + O(\tau^5)

<b>EXPAND</b>

This leads to the following conditions:

:equation:
\left\{ \begin{array}{lcl}
\phantom{1}&\phantom{1}&
\alpha_1 + \alpha_2 = \half            \\
\phantom{1}&\phantom{1}&\phantom{1} \\
\phantom{1}&\phantom{1}&
\alpha_1\eta_{11}+\alpha_2\eta_{21} = {\displaystyle \frac {1}{6}}      \\
\phantom{1}&\phantom{1}&\phantom{1} \\
\phantom{1}&\phantom{1}&
\beta_1 + \beta_2 = 1                            \\
\phantom{1}&\phantom{1}&\phantom{1} \\
\phantom{1}&\phantom{1}&
\beta_1\eta_{11}+\beta_2\eta_{21} = \half            \\
\phantom{1}&\phantom{1}&\phantom{1} \\
\phantom{1}&\phantom{1}&
\beta_1\eta_{11}^2+\beta_2\eta_{21}^2 = {\displaystyle \frac {1}{3}}    \\
\phantom{1}&\phantom{1}&\phantom{1} \\
\phantom{1}&\phantom{1}&
\beta_2\eta_{22} = {\displaystyle \frac {1}{6}}
\end{array} \right.

These can be solved in terms of <tex>$\eta_{11}$</tex> , as follows:

:equation:
\left\{ \begin{array}{lcl}
\phantom{1}&\phantom{1}&
\eta_{21} = {\displaystyle {3\eta_{11}-2 \over 3(2\eta_{11}-1)}}            \\
\phantom{1}&\phantom{1}&\phantom{1} \\
\phantom{1}&\phantom{1}&
\eta_{22} = {\displaystyle {2(3\eta_{11}^2 - 3\eta_{11} + 1)\over
9(4\eta_{11}^2-4\eta_{11}+1)}}      \\
\phantom{1}&\phantom{1}&\phantom{1} \\
\phantom{1}&\phantom{1}&
\alpha_1 = {\displaystyle
{-\eta_{11}+1 \over 4(3\eta_{11}^2 - 3\eta_{11} + 1)}}           \\
\phantom{1}&\phantom{1}&\phantom{1} \\
\phantom{1}&\phantom{1}&
\alpha_2 = {\displaystyle 
{6\eta_{11}^2-5\eta_{11}+1 \over 4(3\eta_{11}^2 - 3\eta_{11}+1)}}  \\
\phantom{1}&\phantom{1}&\phantom{1} \\
\phantom{1}&\phantom{1}&
\beta_1 = {\displaystyle {1\over 4(3\eta_{11}^2 - 3\eta_{11} + 1)}}    \\
\phantom{1}&\phantom{1}&\phantom{1} \\
\phantom{1}&\phantom{1}&
\beta_2 = {\displaystyle 
{3(4\eta_{11}^2-4\eta_{11}+1) \over 4(3\eta_{11}^2 - 3\eta_{11}+1)}}
\end{array} \right.

%\subsubsubsection{Examples}

{\bf 4.1.2.2. Examples}

If we take the standard assumption <tex>$\eta_{11} = 0$</tex> , we get:

:equation:
\label{standard1}
\left\{
\eta_{11} = 0                     \  ; \ 
\eta_{21} = {\textstyle \frac {2}{3}}            \  ; \ 
\eta_{22} = {\textstyle \frac {2}{9}}            \  ; \ 
\alpha_1 = \one{4}            \  ; \ 
\alpha_2 = \one{4}            \  ; \ 
\beta_1 = \one{4}            \  ; \ 
\beta_2 = {\textstyle \frac {3}{4}}
\right\}                               

This produces exactly what <tex>Nystr\"om</tex> (1925) gives this as his simplest
algorithm:

:equation:
\left\{ \begin{array}{lcl}
x_1 &=& x_0 + v_0 \tau + \one{4} \left(k_1 + k_2\right) \tau^2  \\
v_1 &=& v_0 + \one{4}\left(k_1 + 3k_2 \right)\tau  \\
\phantom{1}&\phantom{1}&\phantom{1} \\
k_1 &=& f(x_0) \\
k_2 &=& f(x_0 + {\textstyle\frac{2}{3}} v_0 \tau + 
{\textstyle\frac{2}{9}} k_1\tau^2)
\end{array} \right.

Henrici (1962) also lists this algorithm, refering back to
<tex>Nystr\"om</tex> (1925).
However, Henrici's expressions contain a typo: he lists the last
coefficient as <tex>$\one{3}k_1\tau^2$</tex>.
<tex>Nystr\"om</tex> does list the term correctly,
as <tex>${\textstyle\frac{2}{9}} k_1\tau^2$</tex>.

If we try the other obvious choice <tex>$\eta_{11} = \half$</tex> , we find that
some of the coefficients diverge: <tex>$\eta_{21} = \eta_{21} = \infty$</tex>.
With two force evaluations, it seems not to be possible to let the
first one start right in the middle.

There is a natural choices that leads to relatively
simple expressions for the coefficients: <tex>$\eta_{11}={1\over3}$</tex>.
Here the first force evaluation takes place after one third of the
duration of the time step.  In this case we get:

:equation:
\left\{
\eta_{11} = \one{3}                     \  ; \ 
\eta_{21} = 1                             \  ; \ 
\eta_{22} = {\textstyle \frac {2}{3}}       \  ; \ 
\alpha_1 = \one{2}            \  ; \ 
\alpha_2 = 0                 \  ; \ 
\beta_1 = {\textstyle \frac {3}{4}}           \  ; \ 
\beta_2 = \one{4} 
\right\}

This leads to the following equations:

:equation:
\left\{ \begin{array}{lcl}
x_1 &=& x_0 + v_0 \tau + \one{2} k_1 \tau^2  \\
v_1 &=& v_0 + \one{4}\left(3k_1 + k_2 \right)\tau  \\
\phantom{1}&\phantom{1}&\phantom{1} \\
k_1 &=& f(x_0 + {\textstyle\frac{1}{3}} v_0 \tau) \\
k_2 &=& f(x_0 + v_0 \tau + 
{\textstyle\frac{2}{3}} k_1\tau^2)
\end{array} \right.

A complementary choise is <tex>$\eta_{11}={2\over3}$</tex> , for which the first
force evaluation takes place after two third of the duration of the
time step.  In this case we get:

:equation:
\left\{
\eta_{11} = {\textstyle \frac {2}{3}}                     \  ; \ 
\eta_{21} = 0                             \  ; \ 
\eta_{22} = {\textstyle \frac {2}{3}}       \  ; \ 
\alpha_1 = \one{4}            \  ; \ 
\alpha_2 = \one{4}            \  ; \ 
\beta_1 = {\textstyle \frac {3}{4}}           \  ; \ 
\beta_2 = \one{4} 
\right\}

This leads to the following equations:

:equation:
\left\{ \begin{array}{lcl}
x_1 &=& x_0 + v_0 \tau + \one{4}(k_1 + k_2)\tau^2  \\
v_1 &=& v_0 + \one{4}\left(3k_1 + k_2 \right)\tau  \\
\phantom{1}&\phantom{1}&\phantom{1} \\
k_1 &=& f(x_0 + {\textstyle\frac{2}{3}} v_0 \tau) \\
k_2 &=& f(x_0 + {\textstyle\frac{2}{3}} k_1\tau^2)
\end{array} \right.

There seem to be no other sets of simple coefficients.
We might be tempted to try, say, <tex>$\eta_{11}={1\over4}$</tex> ,
but in that case we get the much more complicated looking set:

:equation:
\left\{
\eta_{11} = \one{4}                     \  ; \ 
\eta_{21} = {\textstyle \frac {5}{6}}                             \  ; \ 
\eta_{22} = {\textstyle \frac {7}{18}}       \  ; \ 
\alpha_1 = {\textstyle \frac {3}{7}}            \  ; \ 
\alpha_2 = \one{14}                 \  ; \ 
\beta_1 = {\textstyle \frac {4}{7}}           \  ; \ 
\beta_2 = {\textstyle \frac {3}{7}}
\right\}

This leads to the following equations:

:equation:
\left\{ \begin{array}{lcl}
x_1 &=& x_0 + v_0 \tau + \one{14} \left(6k_1 + k_2\right) \tau^2  \\
v_1 &=& v_0 + \one{7}\left(4k_1 + 3k_2 \right)\tau  \\
\phantom{1}&\phantom{1}&\phantom{1} \\
k_1 &=& f(x_0 + {\textstyle\frac{1}{4}} v_0 \tau) \\
k_2 &=& f(x_0 + {\textstyle\frac{5}{6}} v_0 \tau + 
{\textstyle\frac{7}{18}} k_1\tau^2)
\end{array} \right.

xxx
